<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Mnemonic bruteforce benchmark</title>
  <script src="webgpu.js"></script>
  <script src="secp256k1.js"></script>
</head>
    <style>
        html, body {
            width: 100%;
            box-sizing: border-box;
            background-color: #222;
            font-size: 15px;
            font-family: 'Courier New', Courier, monospace;
            margin: 0;
            color: bisque;
        }
        html {
            padding: 0;
        }
        body {
            padding: 20px;
        }
        button {
            background-color: #222;
            color: bisque;
            width: 100%;
            height: 40px;
            margin-top: 20px;
        }
        pre {
            text-wrap: auto;
        }
    </style>
<body>
    <button id="benchmark">Start benchmark</button>
    <pre id="output"></pre>
</body>
<script>
function log(text, clear=false) {
    if (clear) window.output.innerHTML = ''
    window.output.innerHTML += text + '\n'
}
document.addEventListener('DOMContentLoaded', () => {

    window.benchmark.onclick = async () => {
        assert(window.isSecureContext, 'WebGPU disabled for http:// protocol, works only on https://')
        assert(navigator.gpu, 'Browser not support WebGPU')
        window.benchmark.style.display = 'none'
        window.output.innerHTML += 'Precompute secp256k1 table... '
        const start = performance.now()
        const precomputeTable = await prepareCompute()
        log(`[${((performance.now() - start) / 1000).toFixed(1)}s]`)
        const adapter1 = await navigator.gpu.requestAdapter({ powerPreference: "high-performance" })
        const device1 = await adapter1.requestDevice()
        await runBenchmark({ precomputeTable, device: device1, adapter: adapter1 })

        const adapter2 = await navigator.gpu.requestAdapter({ powerPreference: "low-power" })
        const device2 = await adapter2.requestDevice()
        if (adapter1.info.device !== adapter2.info.device || adapter1.info.description !== adapter2.info.description) {
            window.output.innerHTML += '\n'
            await runBenchmark({ precomputeTable, device: device2, adapter: adapter2 })
        }
        log('\n✅ DONE')
        window.benchmark.style.display = ''
    }
})
async function runBenchmark(options) {
    const passwords = 1024 * 32
    const { name, clean, inference, buildShader, swapBuffers } =
        await webGPUinit({...options, BUF_SIZE: passwords*128 })
    log(`\n[${name}]\n`)
    window.output.innerHTML += 'Initialize data... '
    const start = performance.now()
    const WORKGROUP_SIZE = 64
    const pipeline = await buildEntirePipeline({
        buildShader, swapBuffers, WORKGROUP_SIZE, hashList: [new Uint8Array([177, 43, 28, 233, 149, 227, 53, 96, 61, 16, 252, 249, 145, 96, 18, 221, 76, 56, 191, 22])],
    })
    const PASSWORD = 'Abbie'
    const digits = passwords.toString(10).length
    const PASS_LEN = Math.ceil((PASSWORD.length + digits + 1) / 4) + 1
    const inp = new Uint32Array(32 + PASS_LEN * passwords).fill(0)
    var strbuf = new Uint8Array(inp.buffer, inp.byteOffset, inp.byteLength)
    const MNEMONIC = 'abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon abandon about'
    strbuf.set(new TextEncoder().encode(MNEMONIC))

    let passwordOffset = 128 + passwords * 4
    for (let i = 0; i < passwords; i++) {
        const curPass = PASSWORD + (i === 35 ? '' : i.toString(10)) + '\n'
        strbuf.set(new TextEncoder().encode(curPass), passwordOffset)
        inp[32 + i] = passwordOffset
        passwordOffset += curPass.length
    }
    bufUint32LESwap(strbuf, 0, 128)
    
    log(`[${((performance.now() - start) / 1000).toFixed(1)}s]\n`)
    for (let mode of ['pbkdf2', 'all']) {
        if (mode === 'pbkdf2') {
            log('\nPbkdf2-hmac-sha512:')
            shaders = [pipeline[0]]
        }
        if (mode === 'all') {
            log('\nMnemonic to address:')
            shaders = pipeline
        }
        await new Promise(res => setTimeout(res, 100)) // flush text
        for (let i = 0; i < 10; i++) {
            const batchSize = 64 * (2 ** i)
            let time = Infinity
            let out
            for (let x = 0; x < 3; x++) {
                const start = performance.now()
                out = await inference({ WORKGROUP_SIZE, shaders, inp, count: batchSize })
                time = Math.min(time, (performance.now() - start) / 1000)
            }
            if (mode === 'all' && out[0] !== 35) {
                log('❌ wgsl pipeline FAILED')
                clean()
                return
            }

            log(`Batch: ${batchSize}, Speed: ${(batchSize / time) | 0} ops/s`);

            if (time > 0.5) {
                break
            }
        }
    }
    clean()
}
</script>
</html>